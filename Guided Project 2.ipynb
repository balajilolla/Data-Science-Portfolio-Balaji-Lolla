{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analyze Hacker Rank Website \"Ask HN\" and \"Show HN\" posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "1. The purpose of this project is to analyze the posts from [Hacker News](https://news.ycombinator.com/) maintained by y combinator\n",
    "2. Utilizing a filtered down readily available dataset, analyze posts that have `Ask HN` or `Show HN` in them. Data source is [Kaggle.com](https://www.kaggle.com/hacker-news/hacker-news-posts)\n",
    "3. Analyze this dataset to see if Ask or Show HN posts receive more comments on average\n",
    "4. Also, peform analysis on the dataset to see if posts created at certail times receive more comments on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Import hacker_news.csv dataset\n",
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "#2. Remove headers from the hn list of lists\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Identify posts that begin with Ask HN or Show HN and put it into a seperate list\n",
    "1. Create 3 seperate lists for ask hn, show hn and other post comments\n",
    "2. Loop through the hn dataset to check if the title begins with ask hn or show hn and assign to the respective lists\n",
    "3. Display total number of posts in each list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts in ask posts: 1744\n",
      "Number of posts in ask posts: 1162\n",
      "Number of posts in ask posts: 17194\n"
     ]
    }
   ],
   "source": [
    "# Create 3 lists called ask_posts, show_posts and other_posts\n",
    "ask_posts=[]\n",
    "show_posts=[]\n",
    "other_posts=[]\n",
    "\n",
    "# Loop through each row in hn\n",
    "for eachrow in hn:\n",
    "    title = eachrow[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(eachrow)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(eachrow)\n",
    "    else:\n",
    "        other_posts.append(eachrow)\n",
    "\n",
    "# Check number of posts in ask_hn, show_hn and other_posts       \n",
    "print('Number of posts in ask posts: ' + str(len(ask_posts)))\n",
    "print('Number of posts in ask posts: ' + str(len(show_posts)))\n",
    "print('Number of posts in ask posts: ' + str(len(other_posts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of `Ask HN` and `Show HN` posts\n",
    "Performing analysis on `Ask HN` or `Show HN` to see if they received more comments on average than other types of posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n",
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "# Declare variable total_ask_comments and set to 0\n",
    "# Get total number of comments in ask_posts dataset and calculate average\n",
    "total_ask_comments = 0\n",
    "for eachrow in ask_posts:\n",
    "    number_of_comments_ask=int(eachrow[4])\n",
    "    total_ask_comments += number_of_comments_ask\n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print(avg_ask_comments)\n",
    "\n",
    "# Declare variable total_show_comments and set to 0\n",
    "# Get total number of comments in show_posts dataset and calculate average\n",
    "total_show_comments = 0\n",
    "for eachrow in show_posts:\n",
    "    number_of_comments_show = int(eachrow[4])\n",
    "    total_show_comments += int(number_of_comments_show)\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "1. On average `Ask HN` posts received 14 comments per post and `Show HN` posts received 10 comments per post\n",
    "2. It can be seen that on an average `Ask HN` posts receive 4 more comments that the `Show HN` posts\n",
    "3. As ask posts receive more comments, focussing the rest of this analysis on these posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part 1\n",
    "1. The analysis for the Ask HN posts is broken down into 2 parts. In this first part we are going to calculate the number of posts created in each hour along with number of comments received\n",
    "2. In the second portion, we are going to calculate average number of comments ask posts received by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'03': 54, '06': 44, '15': 116, '00': 55, '21': 109, '19': 110, '13': 85, '08': 48, '18': 109, '02': 58, '11': 58, '12': 73, '04': 47, '23': 68, '20': 80, '01': 60, '05': 46, '07': 34, '10': 59, '16': 108, '09': 45, '22': 71, '14': 107, '17': 100}\n",
      "{'03': 421, '06': 397, '15': 4477, '00': 447, '21': 1745, '19': 1188, '13': 1253, '08': 492, '18': 1439, '02': 1381, '11': 641, '12': 687, '04': 337, '23': 543, '20': 1722, '01': 683, '05': 464, '07': 267, '10': 793, '16': 1814, '09': 251, '22': 479, '14': 1416, '17': 1146}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import datetime module\n",
    "import datetime as dt\n",
    "\n",
    "# Step 2: Create an empty list called result_list and assign created_at and comments of the post\n",
    "# To create a list of list first an inner list is created which stores these 2 values for each row and appends to a master list\n",
    "result_list = [] # Master list\n",
    "inner_list = []\n",
    "for eachrow in ask_posts:\n",
    "    inner_list=[]\n",
    "    inner_list.append(eachrow[6])\n",
    "    inner_list.append(int(eachrow[4]))\n",
    "    result_list.append(inner_list)\n",
    "\n",
    "# Step 3: Create 2 empty dictionaries called counts_by_hour and comments_by_hour\n",
    "# Segregate hours from the created date and count number of posts for each hour and assign to counts_by_hour\n",
    "# Segregate comments for post by hour and assign to comments_by_hour dictionary\n",
    "counts_by_hour={}\n",
    "comments_by_hour={}\n",
    "for eachrow in result_list:\n",
    "    formatted_date = dt.datetime.strptime(eachrow[0], '%m/%d/%Y %H:%M')\n",
    "    hour_from_date = dt.datetime.strftime(formatted_date, '%H')\n",
    "    if hour_from_date not in counts_by_hour:\n",
    "        counts_by_hour[hour_from_date] = 1\n",
    "        comments_by_hour[hour_from_date] = eachrow[1]\n",
    "    else:\n",
    "        counts_by_hour[hour_from_date] += 1\n",
    "        comments_by_hour[hour_from_date] += eachrow[1]\n",
    "\n",
    "print(counts_by_hour)\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "1. In the second part of this analysis we will use the `counts_by_hour` and `comments_by_hour` dictionaries created in part 1 to find the average number of comments for posts created during each hour of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['03', 7.796296296296297], ['06', 9.022727272727273], ['15', 38.5948275862069], ['00', 8.127272727272727], ['21', 16.009174311926607], ['19', 10.8], ['13', 14.741176470588234], ['08', 10.25], ['18', 13.20183486238532], ['02', 23.810344827586206], ['11', 11.051724137931034], ['12', 9.41095890410959], ['04', 7.170212765957447], ['23', 7.985294117647059], ['20', 21.525], ['01', 11.383333333333333], ['05', 10.08695652173913], ['07', 7.852941176470588], ['10', 13.440677966101696], ['16', 16.796296296296298], ['09', 5.5777777777777775], ['22', 6.746478873239437], ['14', 13.233644859813085], ['17', 11.46]]\n"
     ]
    }
   ],
   "source": [
    "# Using the dictionaries create a list of list called average comments per post\n",
    "# Take the hour from the counts_by_hour dictionary \n",
    "# Calculate average comments by dividing number of comments from comments_by_hour dictionary by the number of posts from counts_by_hour dictionary\n",
    "avg_by_hour=[]\n",
    "for eachhour in counts_by_hour:\n",
    "    avg_by_hour.append([eachhour, comments_by_hour[eachhour]/counts_by_hour[eachhour]])\n",
    "    \n",
    "print(avg_by_hour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final cleanup\n",
    "1. Sort the list of lists by highest number of comments descending\n",
    "2. Print the five highest values in a format that is easier to understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.796296296296297, '03'], [9.022727272727273, '06'], [38.5948275862069, '15'], [8.127272727272727, '00'], [16.009174311926607, '21'], [10.8, '19'], [14.741176470588234, '13'], [10.25, '08'], [13.20183486238532, '18'], [23.810344827586206, '02'], [11.051724137931034, '11'], [9.41095890410959, '12'], [7.170212765957447, '04'], [7.985294117647059, '23'], [21.525, '20'], [11.383333333333333, '01'], [10.08695652173913, '05'], [7.852941176470588, '07'], [13.440677966101696, '10'], [16.796296296296298, '16'], [5.5777777777777775, '09'], [6.746478873239437, '22'], [13.233644859813085, '14'], [11.46, '17']]\n",
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for eachrow in avg_by_hour:\n",
    "    swap_avg_by_hour.append([eachrow[1],eachrow[0]])\n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour,reverse=True)\n",
    "# print(sorted_swap[:5])\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "for eachrow in sorted_swap[:5]:\n",
    "    template_string = '{hour}: {comments:.2f} average comments per post'\n",
    "    result_string=template_string.format(hour=(dt.datetime.strftime(dt.datetime.strptime(eachrow[1],'%H'),'%H:%M')),comments=eachrow[0])\n",
    "    print(result_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "1. The 5 hours when posts should be created to recieve highest number of average comments are 3 PM EST, 2 AM EST, 8 PM EST, 4 PM EST and 9 PM EST\n",
    "2. Other than 2 AM EST, the other times indicate most of the comments are coming from within the US when people get off their work\n",
    "3. The 2 AM time signifies mostly other time zones globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
